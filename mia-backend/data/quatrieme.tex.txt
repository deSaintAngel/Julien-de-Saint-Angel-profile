{15cm} Cette thèse explore les réseaux de neurones à couches hypersphériques pour la détection d'anomalies, en remplaçant les hyperplans traditionnels par des hypersphères. Cette approche, basée sur l'algèbre géométrique conforme, permet, en effectuant une partition non linéaire de l'espace des données, d'offrir une plus grande flexibilité dans la modélisation des frontières de décision. Les couches hypersphériques, applicables aux couches denses et convolutives, sont définies par des hypersphères paramétrées par des centres et des rayons, ajustés lors de l'apprentissage. Une méthode pour l'initialisation des paramètres de ces couches permettant de garantir une convergence stable est proposée. La thèse propose une méthode d'initialisation inspirée de Glorot et Bengio, spécifiquement adaptée aux couches hypersphériques. De nouveaux algorithmes de détection d'anomalies, tels que le Deep SPH SVDD et le Deep M-SPH SVDD, sont également développés, exploitant les hypersphères pour mieux capturer les structures complexes des données. Les expérimentations sur des ensembles de données comme MNIST et CIFAR-10 montrent que ces méthodes sont compétitives par rapport aux approches classiques en termes de performance et d'interprétabilité. Enfin, un théorème d'approximation est établi, démontrant que les réseaux de neurones à couches hypersphériques peuvent approximer des fonctions continues définies sur un compact, ouvrant ainsi des perspectives pour des applications futures dans divers domaines.\\ Mots clés : } } {15cm} This thesis explores hyperspherical neural networks for anomaly detection by replacing traditional hyperplanes with hyperspheres. This approach, based on conformal geometric algebra, enables a nonlinear partitioning of the data space, offering greater flexibility in modeling decision boundaries. Hyperspherical layers, applicable to both dense and convolutional layers, are defined by hyperspheres parameterized by centers and radii, adjusted during training. A method for initializing the parameters of these layers to guarantee stable convergence is proposed. The thesis proposes an initialization method inspired by Glorot and Bengio, specifically adapted for hyperspherical layers. New anomaly detection algorithms, such as Deep sph-SVDD and Deep M sph-SVDD, are also developed, leveraging hyperspheres to better capture complex data structures. Experiments on datasets like MNIST and CIFAR-10 demonstrate that these methods are competitive with classical approaches in terms of performance and interpretability. Finally, an approximation theorem is established, proving that hyperspherical neural networks can approximate continuous functions defined on a compact set, opening perspectives for future applications in various domains.\\ Keywords: } } { p{3cm} p{8cm} p{3cm}} {3cm} & {8cm} \\ 17000 LA ROCHELLE & {3cm}